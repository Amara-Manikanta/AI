{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3faa3634",
   "metadata": {},
   "source": [
    "- Retrieval-Augmented Generation (RAG) is a technique used with large language models (LLMs) that improves their accuracy and relevance by combining the model's text-generation abilities with external information retrieval. \n",
    "- Instead of relying solely on the fixed training data of the model, RAG enables the model to first retrieve relevant information from an external knowledge source such as documents, databases, or APIs. \n",
    "- This retrieved information is then used to augment the model's input, helping it generate responses that are more accurate, up-to-date, and contextually relevant.\n",
    "- The primary purpose of RAG is to reduce hallucinations (where the model generates incorrect or fabricated information), provide domain-specific expertise without retraining the model, supply real-time or updated data, and improve factual accuracy. \n",
    "- It also helps save computational resources since the model itself does not need frequent retraining; rather, updating the external knowledge base suffices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fce094",
   "metadata": {},
   "source": [
    "A simple way to understand RAG:\n",
    "\n",
    "1. You ask a question.\n",
    "\n",
    "2. Before the LLM answers, the system retrieves relevant documents or data related to the question from an external source.\n",
    "\n",
    "3. These documents are provided as context to the LLM.\n",
    "\n",
    "4. The LLM then generates a response based on both the question and the retrieved information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e53ae60",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
