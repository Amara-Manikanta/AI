{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "536c8263",
   "metadata": {},
   "source": [
    "**What is a Large Language Model?**\n",
    "\n",
    "- An LLM is a type of AI model that excels at understanding and generating human language. They are trained on vast amounts of text data, allowing them to learn patterns, structure, and even nuance in language. These models typically consist of many millions of parameters.\n",
    "- Most LLMs nowadays are built on the Transformer architecture—a deep learning architecture based on the “Attention” algorithm, that has gained significant interest since the release of BERT from Google in 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427e0c75",
   "metadata": {},
   "source": [
    "There are 3 types of transformers:\n",
    "\n",
    "1. **Encoders**\n",
    "An encoder-based Transformer takes text (or other data) as input and outputs a dense representation (or embedding) of that text.\n",
    "\n",
    "    **Example:** BERT from Google\n",
    "Use Cases: Text classification, semantic search, Named Entity Recognition\n",
    "Typical Size: Millions of parameters\n",
    "\n",
    "2. **Decoders**\n",
    "A decoder-based Transformer focuses on generating new tokens to complete a sequence, one token at a time.\n",
    "\n",
    "    **Example:** Llama from Meta\n",
    "Use Cases: Text generation, chatbots, code generation\n",
    "Typical Size: Billions (in the US sense, i.e., 10^9) of parameters\n",
    "\n",
    "3. **Seq2Seq (Encoder–Decoder)**\n",
    "A sequence-to-sequence Transformer combines an encoder and a decoder. The encoder first processes the input sequence into a context representation, then the decoder generates an output sequence.\n",
    "\n",
    "    **Example:** T5, BART\n",
    "Use Cases: Translation, Summarization, Paraphrasing\n",
    "Typical Size: Millions of parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22183531",
   "metadata": {},
   "source": [
    "**System Messages**\n",
    "\n",
    "- System messages (also called System Prompts) define how the model should behave. \n",
    "- They serve as persistent instructions, guiding every subsequent interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d990f128",
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "system_message = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"You are a professional customer service agent. Always be polite, clear, and helpful.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7b230d",
   "metadata": {},
   "source": [
    "![hi](/Users/manikantaamara/Desktop/Git/AI/AI_Concepts/polite-alfred.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcd60ee",
   "metadata": {},
   "source": [
    "**Conversations: User and Assistant Messages**\n",
    "\n",
    "A conversation consists of alternating messages between a Human (user) and an LLM (assistant).\n",
    "\n",
    "Chat templates help maintain context by preserving conversation history, storing previous exchanges between the user and the assistant. This leads to more coherent multi-turn conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "112b9aad",
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "conversation = [\n",
    "    {\"role\": \"user\", \"content\": \"I need help with my order\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"I'd be happy to help. Could you provide your order number?\"},\n",
    "    {\"role\": \"user\", \"content\": \"It's ORDER-123\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749e4927",
   "metadata": {},
   "source": [
    "In this example, the user initially wrote that they needed help with their order. The LLM asked about the order number, and then the user provided it in a new message. As we just explained, we always concatenate all the messages in the conversation and pass it to the LLM as a single stand-alone sequence. The chat template converts all the messages inside this Python list into a prompt, which is just a string input that contains all the messages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d72cf3e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
