{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "536c8263",
   "metadata": {},
   "source": [
    "**What is a Large Language Model?**\n",
    "\n",
    "- An LLM is a type of AI model that excels at understanding and generating human language. They are trained on vast amounts of text data, allowing them to learn patterns, structure, and even nuance in language. These models typically consist of many millions of parameters.\n",
    "- Most LLMs nowadays are built on the Transformer architecture—a deep learning architecture based on the “Attention” algorithm, that has gained significant interest since the release of BERT from Google in 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427e0c75",
   "metadata": {},
   "source": [
    "There are 3 types of transformers:\n",
    "\n",
    "1. **Encoders**\n",
    "An encoder-based Transformer takes text (or other data) as input and outputs a dense representation (or embedding) of that text.\n",
    "\n",
    "    **Example:** BERT from Google\n",
    "Use Cases: Text classification, semantic search, Named Entity Recognition\n",
    "Typical Size: Millions of parameters\n",
    "\n",
    "2. **Decoders**\n",
    "A decoder-based Transformer focuses on generating new tokens to complete a sequence, one token at a time.\n",
    "\n",
    "    **Example:** Llama from Meta\n",
    "Use Cases: Text generation, chatbots, code generation\n",
    "Typical Size: Billions (in the US sense, i.e., 10^9) of parameters\n",
    "\n",
    "3. **Seq2Seq (Encoder–Decoder)**\n",
    "A sequence-to-sequence Transformer combines an encoder and a decoder. The encoder first processes the input sequence into a context representation, then the decoder generates an output sequence.\n",
    "\n",
    "    **Example:** T5, BART\n",
    "Use Cases: Translation, Summarization, Paraphrasing\n",
    "Typical Size: Millions of parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22183531",
   "metadata": {},
   "source": [
    "**System Messages**\n",
    "\n",
    "- System messages (also called System Prompts) define how the model should behave. \n",
    "- They serve as persistent instructions, guiding every subsequent interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d990f128",
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "system_message = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"You are a professional customer service agent. Always be polite, clear, and helpful.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7b230d",
   "metadata": {},
   "source": [
    "![hi](/Users/manikantaamara/Desktop/Git/AI/AI_Concepts/polite-alfred.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcd60ee",
   "metadata": {},
   "source": [
    "**Conversations: User and Assistant Messages**\n",
    "\n",
    "A conversation consists of alternating messages between a Human (user) and an LLM (assistant).\n",
    "\n",
    "Chat templates help maintain context by preserving conversation history, storing previous exchanges between the user and the assistant. This leads to more coherent multi-turn conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "112b9aad",
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "conversation = [\n",
    "    {\"role\": \"user\", \"content\": \"I need help with my order\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"I'd be happy to help. Could you provide your order number?\"},\n",
    "    {\"role\": \"user\", \"content\": \"It's ORDER-123\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749e4927",
   "metadata": {},
   "source": [
    "In this example, the user initially wrote that they needed help with their order. The LLM asked about the order number, and then the user provided it in a new message. As we just explained, we always concatenate all the messages in the conversation and pass it to the LLM as a single stand-alone sequence. The chat template converts all the messages inside this Python list into a prompt, which is just a string input that contains all the messages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d72cf3e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ac94c41",
   "metadata": {},
   "source": [
    "### Chat-Templates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99629a95",
   "metadata": {},
   "source": [
    "- Chat templates are essential for structuring conversations between language models and users. They guide how message exchanges are formatted into a single prompt.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15e2880",
   "metadata": {},
   "source": [
    "### Base Models vs. Instruct Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816dd3fc",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Another point we need to understand is the difference between a Base Model vs. an Instruct Model:\n",
    "\n",
    "A Base Model is trained on raw text data to predict the next token.\n",
    "\n",
    "An Instruct Model is fine-tuned specifically to follow instructions and engage in conversations. For example, SmolLM2-135M is a base model, while SmolLM2-135M-Instruct is its instruction-tuned variant.\n",
    "\n",
    "To make a Base Model behave like an instruct model, we need to format our prompts in a consistent way that the model can understand. This is where chat templates come in.\n",
    "\n",
    "ChatML is one such template format that structures conversations with clear role indicators (system, user, assistant)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3d6348",
   "metadata": {},
   "source": [
    "### Understanding Chat Templates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bd7f92",
   "metadata": {},
   "source": [
    "In transformers, chat templates include Jinja2 code that describes how to transform the ChatML list of JSON messages,into a textual representation of the system-level instructions, user messages and assistant responses that the model can understand.\n",
    "\n",
    "This structure helps maintain consistency across interactions and ensures the model responds appropriately to different types of inputs.\n",
    "\n",
    "Below is a simplified version of the SmolLM2-135M-Instruct chat template:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "40affecd",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "{% for message in messages %}\n",
    "{% if loop.first and messages[0]['role'] != 'system' %}\n",
    "<|im_start|>system\n",
    "You are a helpful AI assistant named SmolLM, trained by Hugging Face\n",
    "<|im_end|>\n",
    "{% endif %}\n",
    "<|im_start|>{{ message['role'] }}\n",
    "{{ message['content'] }}<|im_end|>\n",
    "{% endfor %}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1c2130",
   "metadata": {
    "vscode": {
     "languageId": "html"
    }
   },
   "source": [
    "chat_template describes how the list of messages will be formatted.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbc5b7b0",
   "metadata": {
    "vscode": {
     "languageId": "xml"
    }
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant focused on technical topics.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you explain what a chat template is?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"A chat template structures conversations between users and AI models...\"},\n",
    "    {\"role\": \"user\", \"content\": \"How do I use it ?\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed4957f",
   "metadata": {},
   "source": [
    "The previous chat template will produce the following string:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5bc8f68e",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "<|im_start|>system\n",
    "You are a helpful assistant focused on technical topics.<|im_end|>\n",
    "<|im_start|>user\n",
    "Can you explain what a chat template is?<|im_end|>\n",
    "<|im_start|>assistant\n",
    "A chat template structures conversations between users and AI models...<|im_end|>\n",
    "<|im_start|>user\n",
    "How do I use it ?<|im_end|>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d45553a",
   "metadata": {
    "vscode": {
     "languageId": "xml"
    }
   },
   "source": [
    "The transformers library will take care of chat templates for you as part of the tokenization process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57555583",
   "metadata": {},
   "source": [
    "To convert the conversation into a prompt, we load the tokenizer and call apply_chat_template"
   ]
  },
  {
   "cell_type": "raw",
   "id": "47e75466",
   "metadata": {},
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"HuggingFaceTB/SmolLM2-1.7B-Instruct\")\n",
    "rendered_prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adffffe",
   "metadata": {},
   "source": [
    "The rendered_prompt returned by this function is now ready to use as the input for the model you chose!\n",
    "\n",
    "This **apply_chat_template()** function will be used in the backend of your API, when you interact with messages in the ChatML format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c681d15",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
