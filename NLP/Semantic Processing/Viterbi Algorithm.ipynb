{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "471ae171-5855-479e-8ecf-831ebc64088f",
   "metadata": {},
   "source": [
    "# Viterbi Heuristic\n",
    "\n",
    "## Introduction\n",
    "- The **Viterbi Heuristic** is a simplified version of the **Viterbi Algorithm**, which is used to find the most probable sequence of hidden states in a **Hidden Markov Model (HMM)**. \n",
    "- It is typically used in tasks like **part-of-speech tagging**, **speech recognition**, and **machine translation**.\n",
    "\n",
    "## Viterbi Algorithm\n",
    "- The Viterbi algorithm is a dynamic programming algorithm used for decoding the most probable sequence of hidden states in Hidden Markov Models (HMMs), given a sequence of observed events.\n",
    "- It is commonly used in speech recognition, POS tagging, and bioinformatics.\n",
    "### Key Components:\n",
    "1. **States**: Possible hidden states (e.g., POS tags like Noun, Verb).\n",
    "2. **Observations**: Observed events (e.g., words in a sentence).\n",
    "3. **Transition Probabilities (A)**: Probability of transitioning from one state to another.\n",
    "4. **Emission Probabilities (B)**: Probability of observing a particular event given a state.\n",
    "5. **Initial Probabilities (Ï€)**: Probability of starting in a particular state.\n",
    "\n",
    "### Steps:\n",
    "1. **Initialization**: Calculate the probability of starting in each state for the first observation.\n",
    "2. **Recursion**: For each subsequent observation, calculate the probability of arriving at each state from every possible previous state.\n",
    "3. **Termination**: Once the last observation is processed, backtrack to find the best state sequence.\n",
    "4. **Backtracking**: Determine the most probable sequence of states.\n",
    "\n",
    "## Viterbi Heuristic\n",
    "The **Viterbi Heuristic** is a simplified or approximate version of the Viterbi algorithm. It:\n",
    "- **Limits the search space** to likely states.\n",
    "- **Prunes unlikely paths**.\n",
    "- **Uses approximation techniques** to speed up the computation.\n",
    "\n",
    "### Common Techniques:\n",
    "- **Pruning**: Discarding unlikely paths early on.\n",
    "- **Greedy Decisions**: Choosing the most probable state at each step.\n",
    "- **Beam Search**: Keeping the top **k** most likely paths at each step.\n",
    "\n",
    "## Example Use Case\n",
    "### Part-of-Speech Tagging:\n",
    "- Input: \"The cat sleeps.\"\n",
    "- Hidden states: \"DT\" (Determiner), \"NN\" (Noun), \"VBZ\" (Verb).\n",
    "- The Viterbi algorithm finds the most likely sequence of tags for this sentence. The heuristic might simplify by:\n",
    "  - Keeping only the top **k** most likely sequences.\n",
    "  - Pruning unlikely tag transitions.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e7b2cf9-f05e-47fb-a770-82b1f48ddb4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best POS tag sequence: ['DT', 'NN', 'VBZ']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the transition and emission probabilities as dictionaries\n",
    "transition_probs = {\n",
    "    'DT': {'DT': 0.1, 'NN': 0.7, 'VBZ': 0.2},\n",
    "    'NN': {'DT': 0.6, 'NN': 0.3, 'VBZ': 0.1},\n",
    "    'VBZ': {'DT': 0.2, 'NN': 0.3, 'VBZ': 0.5}\n",
    "}\n",
    "\n",
    "emission_probs = {\n",
    "    'DT': {'The': 0.9, 'cat': 0.1, 'sleeps': 0.05},\n",
    "    'NN': {'The': 0.05, 'cat': 0.8, 'sleeps': 0.05},\n",
    "    'VBZ': {'The': 0.05, 'cat': 0.1, 'sleeps': 0.9}\n",
    "}\n",
    "\n",
    "# Observations (words in the sentence)\n",
    "observations = ['The', 'cat', 'sleeps']\n",
    "\n",
    "# Hidden states (POS tags)\n",
    "states = ['DT', 'NN', 'VBZ']\n",
    "\n",
    "# Initialize the Viterbi matrix (stores the highest probabilities)\n",
    "viterbi = {state: [0] * len(observations) for state in states}\n",
    "\n",
    "# Initialize the backpointer matrix (for tracking the best path)\n",
    "backpointer = {state: [None] * len(observations) for state in states}\n",
    "\n",
    "# Step 1: Initialization (first observation)\n",
    "for state in states:\n",
    "    viterbi[state][0] = emission_probs[state].get(observations[0], 0) * 1  # Initial probability (P(start) = 1)\n",
    "\n",
    "# Step 2: Recursion (for subsequent observations)\n",
    "k = 2  # Keep top k most probable states\n",
    "for t in range(1, len(observations)):\n",
    "    word = observations[t]\n",
    "    \n",
    "    for current_state in states:\n",
    "        state_probabilities = []\n",
    "        \n",
    "        for previous_state in states:\n",
    "            transition_prob = transition_probs[previous_state].get(current_state, 0)\n",
    "            emission_prob = emission_probs[current_state].get(word, 0)\n",
    "            prob = viterbi[previous_state][t-1] * transition_prob * emission_prob\n",
    "            state_probabilities.append((prob, previous_state))\n",
    "        \n",
    "        # Sort and keep the top k states\n",
    "        state_probabilities.sort(reverse=True, key=lambda x: x[0])\n",
    "        top_k_states = state_probabilities[:k]\n",
    "        \n",
    "        # Store the most probable path\n",
    "        best_prob, best_state = top_k_states[0]\n",
    "        viterbi[current_state][t] = best_prob\n",
    "        backpointer[current_state][t] = best_state\n",
    "\n",
    "# Step 3: Termination (backtrack to find the best path)\n",
    "# Start from the final time step (last word in the observations)\n",
    "best_final_state = max(viterbi, key=lambda state: viterbi[state][len(observations)-1])\n",
    "best_path = [best_final_state]\n",
    "\n",
    "# Backtrack to find the most probable state sequence\n",
    "for t in range(len(observations)-1, 0, -1):\n",
    "    best_final_state = backpointer[best_final_state][t]\n",
    "    best_path.insert(0, best_final_state)\n",
    "\n",
    "# Output the best path (POS tags sequence)\n",
    "print(\"Best POS tag sequence:\", best_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965219ca-9367-459d-b0c7-3599f872acd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
