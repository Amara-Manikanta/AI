{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Packages used in ML\n",
    "\n",
    "## Key Libraries:\n",
    "- **Numpy**\n",
    "- **Scipy**\n",
    "- **Matplotlib**\n",
    "- **Pandas**\n",
    "- **Scikit-learn**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categories of Machine Learning\n",
    "\n",
    "### Supervised Learning:\n",
    "- **Definition**: The model is trained on a labeled dataset (output is known).\n",
    "- **Goal**: To find hidden patterns in data.\n",
    "- **Types:**\n",
    "  - **Regression**:\n",
    "    - Predicts a continuous value.\n",
    "    - Examples: Predicting house prices, stock trends.\n",
    "    - Algorithms: Linear Regression, Ridge, Lasso, Polynomial Regression.\n",
    "  - **Classification**:\n",
    "    - Predicts a category label.\n",
    "    - Examples: Spam detection, image classification.\n",
    "    - Algorithms: Logistic Regression, SVM, Decision Trees, Random Forest, Neural Networks.\n",
    "\n",
    "- **Regression Algorithms:**\n",
    "  - Ordinal Regression\n",
    "  - Poisson Regression\n",
    "  - Bayesian Linear Regression\n",
    "  - Boosted Decision Tree Regression\n",
    "  - Neural Network Regression\n",
    "\n",
    "### Unsupervised Learning:\n",
    "- **Definition**: The model is trained on unlabeled data (no output provided).\n",
    "- **Goal**: To infer natural structure within data.\n",
    "- **Types:**\n",
    "  - **Clustering**:\n",
    "    - Groups similar objects.\n",
    "    - Algorithms: k-Means, Hierarchical Clustering, DBSCAN.\n",
    "  - **Dimensionality Reduction**:\n",
    "    - Reduces data complexity while retaining key information.\n",
    "    - Algorithms: PCA, t-SNE, SVD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised vs Unsupervised Learning\n",
    "| Feature | Supervised | Unsupervised |\n",
    "|---------|------------|--------------|\n",
    "| **Labeled Data** | Requires labels | No labels required |\n",
    "| **Goal** | Predict outputs | Discover patterns |\n",
    "| **Methods** | Classification, Regression | Clustering, Dimensionality Reduction |\n",
    "| **Applications** | Spam detection, trend prediction | Market basket analysis, anomaly detection |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Techniques\n",
    "## Simple Linear Regression:\n",
    "- **Equation**: y = β0 + β1x + ε\n",
    "  - y: Dependent variable\n",
    "  - x: Independent variable\n",
    "  - β0: Intercept\n",
    "  - β1: Slope\n",
    "  - ε: Error term\n",
    "\n",
    "## Multiple Linear Regression:\n",
    "- **Definition**: Uses multiple independent variables to predict the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation Metrics\n",
    "- **Training Accuracy**: Model's accuracy on training data.\n",
    "  - High training accuracy may indicate overfitting.\n",
    "- **Out-of-Sample Accuracy**:\n",
    "  - Accuracy on unseen data.\n",
    "  - Helps assess generalization capability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.96\n",
      "Out-of-Sample Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create and train the model\n",
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the training set\n",
    "y_train_pred = model.predict(X_train)\n",
    "# Calculate training accuracy\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "# Predict on the test set\n",
    "y_test_pred = model.predict(X_test)\n",
    "# Calculate out-of-sample (test) accuracy\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy:.2f}\")\n",
    "print(f\"Out-of-Sample Accuracy: {test_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold Cross-Validation\n",
    "- **Definition**: Splits data into k subsets, trains on k-1 subsets, validates on the remaining subset.\n",
    "- **Benefits**:\n",
    "  - Better data utilization.\n",
    "  - Reduced overfitting.\n",
    "  - Reliable performance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores: [1.         1.         0.93333333 0.96666667 0.96666667]\n",
      "Mean CV Score: 0.97\n",
      "Standard Deviation of CV Score: 0.02\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Create a logistic regression model\n",
    "model = LogisticRegression(max_iter=200)\n",
    "\n",
    "# Set up K-Fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "cv_scores = cross_val_score(model, X, y, cv=kf)\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print(f\"Cross-Validation Scores: {cv_scores}\")\n",
    "print(f\"Mean CV Score: {cv_scores.mean():.2f}\")\n",
    "print(f\"Standard Deviation of CV Score: {cv_scores.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "1. **R-Squared (R²)**:\n",
    "   - Proportion of variance explained by the model.\n",
    "   - Higher values indicate a better fit.\n",
    "2. **Mean Absolute Error (MAE)**:\n",
    "   - Average of absolute differences between predictions and actuals.\n",
    "3. **Mean Squared Error (MSE)**:\n",
    "   - Average of squared differences between predictions and actuals.\n",
    "4. **Root Mean Squared Error (RMSE)**:\n",
    "   - Square root of MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Typical Machine Learning Workflow\n",
    "\n",
    "1. **Data Collection:** Gather relevant and clean data from various sources.\n",
    "2. **Data Preprocessing:** Handle missing values, encode categorical variables, normalize/scale features.\n",
    "3. **Feature Selection/Engineering:** Identify important attributes, create new features if necessary.\n",
    "4. **Model Selection:** Choose the right algorithm for the problem (e.g., regression, classification, clustering).\n",
    "5. **Model Training:** Fit the model to the training data.\n",
    "6. **Model Evaluation:** Assess model performance using appropriate metrics and validation strategies.\n",
    "7. **Hyperparameter Tuning:** Adjust algorithm parameters for better accuracy and generalization.\n",
    "8. **Deployment:** Integrate the model into production systems for real-world use.\n",
    "\n",
    "# Common Challenges in Machine Learning\n",
    "\n",
    "- **Overfitting:** Model performs well on training data but poorly on unseen data.\n",
    "- **Underfitting:** Model is too simple to capture underlying patterns.\n",
    "- **Imbalanced Data:** Unequal class distribution affect classification performance.\n",
    "- **Data Leakage:** When information from outside the training dataset is used to create the model, leading to overly optimistic results.\n",
    "\n",
    "# Good Practices\n",
    "\n",
    "- Use **cross-validation** to validate models more reliably.\n",
    "- Always keep **test data** separate for final evaluation.\n",
    "- Perform **feature scaling** where required.\n",
    "- Regularly visualize data and results to spot issues and interpret findings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
